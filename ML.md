# Sophia.github.io
<h1/>机器学习</h1>
<!-- TOC -->

- [偏差与方差](#偏差与方差)
    - [导致偏差和方差的原因](#导致偏差和方差的原因)
    - [深度学习中的偏差与方差](#深度学习中的偏差与方差)
    - [偏差/方差 与 Boosting/Bagging](#偏差方差-与-boostingbagging)
    - [偏差与方差的计算公式](#偏差与方差的计算公式)
    - [偏差与方差的权衡（过拟合与模型复杂度的权衡）](#偏差与方差的权衡过拟合与模型复杂度的权衡)
- [生成模型与判别模型](#生成模型与判别模型)
- [先验概率与后验概率](#先验概率与后验概率)
- [QA](#QA)
    - [准确率的局限性](#准确率的局限性)
    - [ROC曲线](#ROC曲线)
<!-- /TOC -->


## 偏差与方差
> 《机器学习》 2.5 偏差与方差 - 周志华
- **偏差**与**方差**分别是用于衡量一个模型**泛化误差**的两个方面；
  - 模型的**偏差**，指的是模型预测的**期望值**与**真实值**之间的差；
  - 模型的**方差**，指的是模型预测的**期望值**与**预测值**之间的差平方和；
- 在**监督学习**中，模型的**泛化误差**可**分解**为偏差、方差与噪声之和。

- **偏差**用于描述模型的**拟合能力**；<br/>
  **方差**用于描述模型的**稳定性**。

### 导致偏差和方差的原因
- **偏差**通常是由于我们对学习算法做了**错误的假设**，或者模型的复杂度不够；
  - 比如真实模型是一个二次函数，而我们假设模型为一次函数，这就会导致偏差的增大（欠拟合）；
  - **由偏差引起的误差**通常在**训练误差**上就能体现，或者说训练误差主要是由偏差造成的
- **方差**通常是由于**模型的复杂度相对于训练集过高**导致的；
  - 比如真实模型是一个简单的二次函数，而我们假设模型是一个高次函数，这就会导致方差的增大（过拟合）；
  - **由方差引起的误差**通常体现在测试误差相对训练误差的**增量**上。
## QA
### 准确率的局限性
- 准确率使之**分类正确的样本**占**总样本**个数的比例。如果**样本不均衡**的话，即，正确的样本本来就占所有数据的大部分的话，即使准确率很高，也不能代表模型的有效性。
### ROC曲线
- ROC横坐标为假阳性率FPR, 纵坐标为真阳性率TPR
- FPR=FP/N
- TPR=TP/N
