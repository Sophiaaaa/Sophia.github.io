# Sophia.github.io
<h1/>机器学习</h1>
<!-- TOC -->

- [偏差与方差](#偏差与方差)
    - [导致偏差和方差的原因](#导致偏差和方差的原因)
    - [深度学习中的偏差与方差](#深度学习中的偏差与方差)
    - [偏差/方差 与 Boosting/Bagging](#偏差方差-与-boostingbagging)
    - [偏差与方差的计算公式](#偏差与方差的计算公式)
    - [偏差与方差的权衡（过拟合与模型复杂度的权衡）](#偏差与方差的权衡过拟合与模型复杂度的权衡)
- [生成模型与判别模型](#生成模型与判别模型)
- [先验概率与后验概率](#先验概率与后验概率)
- [QA](#QA)
    - [准确率的局限性](#准确率的局限性)
    - [ROC曲线](#ROC曲线)
    - [模型评估过程中，有哪些主要的验证方法，它们的优缺点是什么](#模型评估过程中，有哪些主要的验证方法，它们的优缺点是什么)
<!-- /TOC -->


## 偏差与方差
> 《机器学习》 2.5 偏差与方差 - 周志华
- **偏差**与**方差**分别是用于衡量一个模型**泛化误差**的两个方面；
  - 模型的**偏差**，指的是模型预测的**期望值**与**真实值**之间的差；
  - 模型的**方差**，指的是模型预测的**期望值**与**预测值**之间的差平方和；
- 在**监督学习**中，模型的**泛化误差**可**分解**为偏差、方差与噪声之和。

- **偏差**用于描述模型的**拟合能力**；<br/>
  **方差**用于描述模型的**稳定性**。

### 导致偏差和方差的原因
- **偏差**通常是由于我们对学习算法做了**错误的假设**，或者模型的复杂度不够；
  - 比如真实模型是一个二次函数，而我们假设模型为一次函数，这就会导致偏差的增大（欠拟合）；
  - **由偏差引起的误差**通常在**训练误差**上就能体现，或者说训练误差主要是由偏差造成的
- **方差**通常是由于**模型的复杂度相对于训练集过高**导致的；
  - 比如真实模型是一个简单的二次函数，而我们假设模型是一个高次函数，这就会导致方差的增大（过拟合）；
  - **由方差引起的误差**通常体现在测试误差相对训练误差的**增量**上。
### 导致偏差和方差的原因
- **偏差**通常是由于我们对学习算法做了**错误的假设**，或者模型的复杂度不够；
  - 比如真实模型是一个二次函数，而我们假设模型为一次函数，这就会导致偏差的增大（欠拟合）；
  - **由偏差引起的误差**通常在**训练误差**上就能体现，或者说训练误差主要是由偏差造成的
- **方差**通常是由于**模型的复杂度相对于训练集过高**导致的；
  - 比如真实模型是一个简单的二次函数，而我们假设模型是一个高次函数，这就会导致方差的增大（过拟合）；
  - **由方差引起的误差**通常体现在测试误差相对训练误差的**增量**上。

### 深度学习中的偏差与方差
- 神经网络的拟合能力非常强，因此它的**训练误差**（偏差）通常较小；
- 但是过强的拟合能力会导致较大的方差，使模型的测试误差（**泛化误差**）增大；
- 因此深度学习的核心工作之一就是研究如何降低模型的泛化误差，这类方法统称为**正则化方法**。
### 偏差与方差的权衡（过拟合与模型复杂度的权衡）
- 给定学习任务，
  - 当训练不足时，模型的**拟合能力不够**（数据的扰动不足以使模型产生显著的变化），此时**偏差**主导模型的泛化误差；
  - 随着训练的进行，模型的**拟合能力增强**（模型能够学习数据发生的扰动），此时**方差**逐渐主导模型的泛化误差；
  - 当训练充足后，模型的**拟合能力过强**（数据的轻微扰动都会导致模型产生显著的变化），此时即发生**过拟合**（训练数据自身的、非全局的特征也被模型学习了）

- 偏差和方差的关系和**模型容量**（模型复杂度）、**欠拟合**和**过拟合**的概念紧密相联
  <div align="center"><img src="../_assets/TIM截图20180817214034.png" height="" /></div>

  - 当模型的容量增大（x 轴）时， 偏差（用点表示）随之减小，而方差（虚线）随之增大
  - 沿着 x 轴存在**最佳容量**，**小于最佳容量会呈现欠拟合**，**大于最佳容量会导致过拟合**。
  > 《深度学习》 5.4.4 权衡偏差和方差以最小化均方误差

## QA
### 准确率的局限性
- 准确率使之**分类正确的样本**占**总样本**个数的比例。如果**样本不均衡**的话，即，正确的样本本来就占所有数据的大部分的话，即使准确率很高，也不能代表模型的有效性。
### ROC曲线
- ROC横坐标为假阳性率FPR, 纵坐标为真阳性率TPR
- FPR=FP/N
- TPR=TP/N
### 模型评估过程中，有哪些主要的验证方法，它们的优缺点是什么
- **Holdout检验**将原始的样本集合随机划分成训练集和验证集两个部分。其缺点很明显，即在验证集上计算出来的最后评估指标与**原始分组**有很大关系。
- **交叉验证**将全部样本划分成k个大小相等的样本子集，依次遍历这k个子集，每次把当前子集作为验证集，其余所有子集作为训练集，进行模型的训练和评估，最终把k次评估指标的平均值作为最终的评估指标。缺点是，当样本数量较小的时候，会影响训练效果。
- **自助法**对于总数为n的样本集合，进行n次有放回的随机抽样，得到大小为n的训练集。而完全没有被抽到的样本作为验证集。优点是适合样本数量较小的情况。
